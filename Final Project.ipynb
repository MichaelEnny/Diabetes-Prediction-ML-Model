{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d03f9485",
   "metadata": {},
   "source": [
    "## Assignment_Week5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c800803",
   "metadata": {},
   "source": [
    "**Instructions:**\n",
    "\n",
    "- Submit your work as a `.ipynb` notebook file on blackboard.\n",
    "\n",
    "- Please name your `.ipynb` file using the following format: `firstname_Assignment_Week5.ipynb`\n",
    "\n",
    "\n",
    "**This assignment has two parts - first, implementing decision trees, random forests, and GBRT (optional) on the heart disease dataset. Second, proposing a machine learning project idea for the 540 course project. We've now covered many machine learning algorithms for both regression and classification. It's time to start thinking about potential projects to apply what you've learned.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25699ba1",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f33c72d",
   "metadata": {},
   "source": [
    "### Part 1: Exploring Decision Trees, Random Forests, and GBRT on Heart Disease Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2014907",
   "metadata": {},
   "source": [
    "**Goal**: In this part, we implemented and tuned Decision Trees, Random Forests, and Gradient Boosted Regression Trees(optional) on a heart disease dataset, comparing their performances to determine the best technique for the given data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3bfba8",
   "metadata": {},
   "source": [
    "### About Dataset\n",
    "\n",
    "#### Context\n",
    "This data set dates from 1988 and consists of four databases: Cleveland, Hungary, Switzerland, and Long Beach V. It contains 76 attributes, including the predicted attribute, but all published experiments refer to using a subset of 14 of them. \n",
    "\n",
    "\n",
    "#### Attribute Information:\n",
    "- age: Age of the patient.\n",
    "- sex: Gender (1 for male and 0 for female).\n",
    "- cp: Chest pain type (with four distinct types represented by numbers 1-4).\n",
    "- trestbps: Resting blood pressure (in mm Hg upon admission to the hospital).\n",
    "- chol: Serum cholesterol in mg/dl.\n",
    "- fbs: Fasting blood sugar > 120 mg/dl (1 = true; 0 = false).\n",
    "- restecg: Resting electrocardiographic results (values 0,1,2).\n",
    "- thalach: Maximum heart rate achieved.\n",
    "- exang: Exercise-induced angina (1 = yes; 0 = no).\n",
    "- oldpeak: ST depression induced by exercise relative to rest.\n",
    "- slope: The slope of the peak exercise ST segment.\n",
    "- ca: Number of major vessels (0-3) colored by fluoroscopy.\n",
    "- thal: A short for thalassemia, a blood disorder (3 = normal; 6 = fixed defect; 7 = reversible defect).\n",
    "\n",
    "\n",
    "- **hd**: Presence of heart disease (1 = true; 0 = false)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe82ad0",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14568748",
   "metadata": {},
   "source": [
    "### Task 1: Load the Dataset and Check Basic Information\n",
    "- Check data structure, variables, and potential issues (like missing values)   \n",
    " *There's no specific requirement for what to check; choose what you feel is most relevant and informative. (for example, the shape of the dataset, Summary of the data)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c68a9c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import packages\n",
    "import mglearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f577a0d5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\wisdo\\\\ANA 540 - Adavanced Data Analytics\\\\Week 05\\\\Assignment'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "963cd362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>restbp</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>hd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  restbp   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0    63.0  1.0  1.0   145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1    67.0  1.0  4.0   160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2    67.0  1.0  4.0   120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3    37.0  1.0  3.0   130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4    41.0  0.0  2.0   130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "..    ...  ...  ...     ...    ...  ...      ...      ...    ...      ...   \n",
       "298  45.0  1.0  1.0   110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "299  68.0  1.0  4.0   144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "300  57.0  1.0  4.0   130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "301  57.0  0.0  2.0   130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "302  38.0  1.0  3.0   138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  hd  \n",
       "0      3.0  0.0  6.0   0  \n",
       "1      2.0  3.0  3.0   1  \n",
       "2      2.0  2.0  7.0   1  \n",
       "3      3.0  0.0  3.0   0  \n",
       "4      1.0  0.0  3.0   0  \n",
       "..     ...  ...  ...  ..  \n",
       "298    2.0  0.0  7.0   1  \n",
       "299    2.0  2.0  7.0   1  \n",
       "300    2.0  1.0  7.0   1  \n",
       "301    2.0  1.0  3.0   1  \n",
       "302    1.0    ?  3.0   0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Dataset \n",
    "data = pd.read_csv(\"C:\\\\Users\\\\wisdo\\\\OneDrive\\\\Desktop\\\\MCDaniel\\\\CourseWork\\\\ANA 540\\\\week 05\\\\Assignment\\\\heart disease.csv\")\n",
    "# Convert the dataset to a DataFrame\n",
    "heartd_df = pd.DataFrame(data)\n",
    "heartd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77df81be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  sex   cp  restbp   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0  63.0  1.0  1.0   145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
      "1  67.0  1.0  4.0   160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
      "2  67.0  1.0  4.0   120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
      "3  37.0  1.0  3.0   130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
      "4  41.0  0.0  2.0   130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
      "\n",
      "   slope   ca thal  hd  \n",
      "0    3.0  0.0  6.0   0  \n",
      "1    2.0  3.0  3.0   1  \n",
      "2    2.0  2.0  7.0   1  \n",
      "3    3.0  0.0  3.0   0  \n",
      "4    1.0  0.0  3.0   0  \n"
     ]
    }
   ],
   "source": [
    "# Examine Basic Information\n",
    "print(heartd_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d61b40b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    }
   ],
   "source": [
    "#Checking the shape\n",
    "print(heartd_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a905569a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age        0\n",
      "sex        0\n",
      "cp         0\n",
      "restbp     0\n",
      "chol       0\n",
      "fbs        0\n",
      "restecg    0\n",
      "thalach    0\n",
      "exang      0\n",
      "oldpeak    0\n",
      "slope      0\n",
      "ca         0\n",
      "thal       0\n",
      "hd         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Checking missing values\n",
    "print(heartd_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9df20708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   age      303 non-null    float64\n",
      " 1   sex      303 non-null    float64\n",
      " 2   cp       303 non-null    float64\n",
      " 3   restbp   303 non-null    float64\n",
      " 4   chol     303 non-null    float64\n",
      " 5   fbs      303 non-null    float64\n",
      " 6   restecg  303 non-null    float64\n",
      " 7   thalach  303 non-null    float64\n",
      " 8   exang    303 non-null    float64\n",
      " 9   oldpeak  303 non-null    float64\n",
      " 10  slope    303 non-null    float64\n",
      " 11  ca       303 non-null    object \n",
      " 12  thal     303 non-null    object \n",
      " 13  hd       303 non-null    int64  \n",
      "dtypes: float64(11), int64(1), object(2)\n",
      "memory usage: 33.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#Checking columns and their data types\n",
    "heartd_df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dd2aebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>restbp</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>hd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.438944</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>3.158416</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.600660</td>\n",
       "      <td>0.458746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.038662</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>0.960126</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>0.499120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp      restbp        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.438944    0.679868    3.158416  131.689769  246.693069    0.148515   \n",
       "std      9.038662    0.467299    0.960126   17.599748   51.776918    0.356198   \n",
       "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
       "50%     56.000000    1.000000    3.000000  130.000000  241.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  275.000000    0.000000   \n",
       "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          hd  \n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000  \n",
       "mean     0.990099  149.607261    0.326733    1.039604    1.600660    0.458746  \n",
       "std      0.994971   22.875003    0.469794    1.161075    0.616226    0.499120  \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000  \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000  \n",
       "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000  \n",
       "75%      2.000000  166.000000    1.000000    1.600000    2.000000    1.000000  \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    1.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generating descriptive statistics\n",
    "heartd_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260da6a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ca3deaa",
   "metadata": {},
   "source": [
    "### Task 2: Handle Missing Values\n",
    "Ensure the dataset is free from missing values to prevent issues during modeling.\n",
    "- For this dataset, missing values are represented as '?'.\n",
    "- For this task, choose to simply remove all rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98a2529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "015ce598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "# Replacing all occurrences of '?' with NaN (missing values)\n",
    "heartd_df.replace('?', pd.NA, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4fada75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>restbp</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>hd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  restbp   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0    63.0  1.0  1.0   145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1    67.0  1.0  4.0   160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2    67.0  1.0  4.0   120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3    37.0  1.0  3.0   130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4    41.0  0.0  2.0   130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "..    ...  ...  ...     ...    ...  ...      ...      ...    ...      ...   \n",
       "292  57.0  0.0  4.0   140.0  241.0  0.0      0.0    123.0    1.0      0.2   \n",
       "293  45.0  1.0  1.0   110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "294  68.0  1.0  4.0   144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "295  57.0  1.0  4.0   130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "296  57.0  0.0  2.0   130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  hd  \n",
       "0      3.0  0.0  6.0   0  \n",
       "1      2.0  3.0  3.0   1  \n",
       "2      2.0  2.0  7.0   1  \n",
       "3      3.0  0.0  3.0   0  \n",
       "4      1.0  0.0  3.0   0  \n",
       "..     ...  ...  ...  ..  \n",
       "292    2.0  0.0  7.0   1  \n",
       "293    2.0  0.0  7.0   1  \n",
       "294    2.0  2.0  7.0   1  \n",
       "295    2.0  1.0  7.0   1  \n",
       "296    2.0  1.0  3.0   1  \n",
       "\n",
       "[297 rows x 14 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing rows with missing values\n",
    "heartd_df.dropna(inplace=True)\n",
    "\n",
    "# Reseting the index\n",
    "heartd_df.reset_index(drop=True, inplace=True)\n",
    "heartd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0b0754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86c41081",
   "metadata": {},
   "source": [
    "### Task 3: One-Hot Encoding\n",
    "\n",
    "- 1. Use the `pd.get_dummies()` function or an equivalent method to perform one-hot encoding \n",
    "- 2. Display the first few rows of the transformed dataset to verify the encoding.\n",
    "- 3. Check the shape of the dataset after encoding\n",
    "\n",
    "These are categorical variables and their levels in this dataset\n",
    "\n",
    "- **sex** - **Category**\n",
    "  - 0 = female\n",
    "  - 1 = male\n",
    "- **cp**, chest pain, **Category**\n",
    "  - 1 = typical angina\n",
    "  - 2 = atypical angina\n",
    "  - 3 = non-anginal pain\n",
    "  - 4 = asymptomatic\n",
    "- **fbs**, fasting blood sugar, **Category**\n",
    "  - 0 = >=120 mg/dl\n",
    "  - 1 = <120 mg/dl\n",
    "- **restecg**, resting electrocardiographic results, **Category**\n",
    "  - 1 = normal\n",
    "  - 2 = having ST-T wave abnormality\n",
    "  - 3 = showing probable or definite left ventricular hypertrophy\n",
    "- **exang**, exercise induced angina, **Category**\n",
    "  - 0 = no\n",
    "  - 1 = yes\n",
    "- **slope**, the slope of the peak exercise ST segment, **Category**\n",
    "  - 1 = upsloping\n",
    "  - 2 = flat\n",
    "  - 3 = downsloping\n",
    "- **thal**, thalium heart scan, **Category**\n",
    "  - 3 = normal (no cold spots)\n",
    "  - 6 = fixed defect (cold spots during rest and exercise)\n",
    "  - 7 = reversible defect (when cold spots only appear during exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8b1d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
    "df_encoded = pd.get_dummies(heartd_df, columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a787e194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  restbp   chol  thalach  oldpeak   ca  hd  sex_0.0  sex_1.0  cp_1.0  \\\n",
      "0  63.0   145.0  233.0    150.0      2.3  0.0   0        0        1       1   \n",
      "1  67.0   160.0  286.0    108.0      1.5  3.0   1        0        1       0   \n",
      "2  67.0   120.0  229.0    129.0      2.6  2.0   1        0        1       0   \n",
      "3  37.0   130.0  250.0    187.0      3.5  0.0   0        0        1       0   \n",
      "4  41.0   130.0  204.0    172.0      1.4  0.0   0        1        0       0   \n",
      "\n",
      "   ...  restecg_1.0  restecg_2.0  exang_0.0  exang_1.0  slope_1.0  slope_2.0  \\\n",
      "0  ...            0            1          1          0          0          0   \n",
      "1  ...            0            1          0          1          0          1   \n",
      "2  ...            0            1          0          1          0          1   \n",
      "3  ...            0            0          1          0          0          0   \n",
      "4  ...            0            1          1          0          1          0   \n",
      "\n",
      "   slope_3.0  thal_3.0  thal_6.0  thal_7.0  \n",
      "0          1         0         1         0  \n",
      "1          0         1         0         0  \n",
      "2          0         0         0         1  \n",
      "3          1         1         0         0  \n",
      "4          0         1         0         0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the transformed dataset\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e9d6f463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the encoded dataset: (297, 26)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the encoded dataset\n",
    "print(\"Shape of the encoded dataset:\", df_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4551de0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34463e8d",
   "metadata": {},
   "source": [
    "### Task 4: Split the Data into Training and Test Sets\n",
    "  - Split the data into 75% training and 25% test sets. \n",
    "    \n",
    "  - Use random_state=42\n",
    "  - Verify the sizes of the training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e65d698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the target variable\n",
    "y = heartd_df['hd']\n",
    "\n",
    "# Define the features, excluding the target variable\n",
    "X = heartd_df.drop(columns=['hd'])\n",
    "\n",
    "# Split the data into training and test sets (75% training, 25% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "107eed91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 222\n",
      "Test set size: 75\n"
     ]
    }
   ],
   "source": [
    "# Verify the sizes of the training and test datasets\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d477aab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25562e89",
   "metadata": {},
   "source": [
    "### Task 5: Build A Preliminary Classification Tree\n",
    "- Initialize a Decision Tree classifier. You can use the default parameters for the initial model.\n",
    "- Fit the classifier using the training data.\n",
    "\n",
    "- Calculate and display the accuracy of the classifier on both the training and test datasets to see its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b1c2d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78f07ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Decision Tree classifier (using default parameters)\n",
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5cc334dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the classifier using the training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "70fbd750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Predicting on the training and test data\n",
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "# Calculating and display the accuracy on both the training and test datasets\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dfca54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95b1f83f",
   "metadata": {},
   "source": [
    "**Question: Given the results of the Training Accuracy score and Test Accuracy score for this initial model, would you consider this model to be overfitting? Why or why not?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01831cda",
   "metadata": {},
   "source": [
    "The Training Accuracy score of 1.0 (100%) and the Test Accuracy score of 0.81 (81%) indicate that there is a significant difference in performance between the training and test datasets. In this context, this discrepancy suggests that the initial model is likely overfitting.\n",
    "\n",
    "Here's why:\n",
    "\n",
    "- Training Accuracy of 1.0: A Training Accuracy score of 1.0 means that the model has perfectly fit the training data, achieving 100% accuracy. It suggests that the model has essentially memorized the training data and can make perfect predictions on it.\n",
    "\n",
    "- Test Accuracy of 0.81: While a Test Accuracy of 0.81 is relatively good, it's significantly lower than the Training Accuracy. This drop in accuracy when moving from the training dataset to the test dataset is a strong indicator of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea452e9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80a1b43f",
   "metadata": {},
   "source": [
    "### Task 6: Tune Parameters of the Decision Tree\n",
    "\n",
    "Given that we've built a preliminary decision tree, now explore how tuning parameters can influence its performance. In our decision tree lectures and the accompanying notebooks, we discussed and displayed pre-pruning. We also touched upon Cost Complexity Pruning in last week's instructional notebook. In this assignment, we practice pre-pruning using the `max_depth` parameter.\n",
    "- Initialize a Decision Tree classifier. This time, set the `max_depth` parameter to 3 to limit the depth of the tree. \n",
    "- Ensure you also set `random_state=42` for consistent results.\n",
    "- Fit the classifier with the training data.\n",
    "- Calculate and display the accuracy of the classifier on both the training and test datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "34c55387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Decision Tree classifier with max_depth=3 (pre-pruning)\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "81e6a6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=42)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the classifier using the training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2262b47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.85\n",
      "Test Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Predict on the training and test data\n",
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "# Calculate and display the accuracy on both the training and test datasets\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb303e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c49a33fb",
   "metadata": {},
   "source": [
    "**Question: Based on the accuracy scores you've obtained after constraining the tree depth, how do you think limiting the max_depth parameter affects the model's ability to generalize to unseen data? Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8178b1ff",
   "metadata": {},
   "source": [
    "When limiting the max_depth parameter of a Decision Tree classifier, we are essentially restricting the depth of the tree,\n",
    "which, in turn, limits the complexity of the model. Here, max_depth=3, which means the tree can only have \n",
    "a maximum depth of 3 levels.\n",
    "\n",
    "Here's how limiting the max_depth parameter affects the model's ability to generalize to unseen data:\n",
    "\n",
    "- Training Accuracy (0.85): The training accuracy is still relatively high but lower than what was achieved with the unpruned tree (Training Accuracy: 1.0). This indicates that the model has reduced overfitting on the training data.\n",
    "\n",
    "- Test Accuracy (0.81): The test accuracy is similar to what is achieved with the unpruned tree (Test Accuracy: 0.81). This suggests that limiting the max_depth parameter has not significantly harmed the model's ability to generalize to unseen data. The test accuracy remains reasonably high, indicating that the model still performs well on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52f8b26",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da80a900",
   "metadata": {},
   "source": [
    "### Task 7: Explore Random Forests\n",
    "\n",
    "Now that you've experimented with a single decision tree, let's explore how combining multiple trees can improve performance.\n",
    "- Import the necessary libraries for Random Forest.\n",
    "- Initialize a Random Forest classifier. *You can either build an initial model with default parameters, or choose to experiment with other parameters, such as n_estimators=100, max_depth=5*\n",
    "- Fit the Random Forest classifier using the training data.\n",
    "- Calculate and display the accuracy of the Random Forest classifier on both the training and test datasets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "66ec433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "74f44abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimenting with specific parameters of random forest classifier\n",
    "rf_classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fb16494f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "52cea4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.00\n",
      "Test Accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "train_predictions = rf_classifier.predict(X_train)\n",
    "test_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d8fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1533a8e",
   "metadata": {},
   "source": [
    "**Question: Comparing the accuracy scores of the Random Forest and the single decision tree, which model performed better? Would we lean towards choosing the Random Forest? Why or why not?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9732e02",
   "metadata": {},
   "source": [
    "Comparing the accuracy scores of the Random Forest and the single Decision Tree:\n",
    "\n",
    "Random Forest:\n",
    "\n",
    "- Training Accuracy: 1.00\n",
    "- Test Accuracy: 0.87\n",
    "\n",
    "Single Decision Tree (with max_depth=3):\n",
    "\n",
    "- Training Accuracy: 0.85\n",
    "- Test Accuracy: 0.81\n",
    "\n",
    "In terms of accuracy, the Random Forest outperforms the single Decision Tree on both the training and test datasets. The Random Forest has higher Training Accuracy (1.00 vs. 0.85) and Test Accuracy (0.87 vs. 0.81).\n",
    "\n",
    "Random Forest is the preferred choice because it performs better in terms of accuracy and generalization to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b55488",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3be831c3",
   "metadata": {},
   "source": [
    "### Task 8: Investigate Feature Importance with Random Forests\n",
    "Gain insights into the most influential features in the dataset using the Random Forest model.\n",
    "\n",
    "- Extract the feature importances from the trained Random Forest model. The `feature_importances_` attribute of the model provides this information.\n",
    "- Optional: Visualize the feature importances using a bar chart for better clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b0776cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importances\n",
    "feature_importances = rf_classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1663e0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA28AAAIhCAYAAADZ6oJUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABYbklEQVR4nO3de1yUZf7/8fcIwiADqOABDQXFAyqeDwnmYdVIzTK3TC3TKMvS1DzzRVQ0z1mapVtqqZ3MNd0yS02NPJuamptkKhq2UnkKFBM53L8/+jG7I2CK4HDD6/l43I8Hc8913/fnmmuree9139dYDMMwBAAAAAAo0ko5uwAAAAAAwF8jvAEAAACACRDeAAAAAMAECG8AAAAAYAKENwAAAAAwAcIbAAAAAJgA4Q0AAAAATIDwBgAAAAAmQHgDAAAAABMgvAEA8m3p0qWyWCy5bqNGjSqUax45ckSTJk3SqVOnCuX8t+PUqVOyWCx6+eWXnV1Kvu3cuVOTJk3S77//7uxSAADXcXV2AQAA83vnnXdUt25dh31VqlQplGsdOXJEsbGxat++vQIDAwvlGiXZzp07FRsbqwEDBqhs2bLOLgcA8D8IbwCA29agQQM1b97c2WXclvT0dFksFrm6lsz/NP7xxx+yWq3OLgMAcAPcNgkAKHQfffSRWrduLU9PT9lsNkVEROjAgQMObfbt26fevXsrMDBQHh4eCgwMVJ8+ffTTTz/Z2yxdulSPPPKIJKlDhw72WzSXLl0qSQoMDNSAAQNyXL99+/Zq3769/XVcXJwsFoveffddjRw5UlWrVpW7u7uOHz8uSdq0aZM6duwob29vlSlTRuHh4dq8eXO++p59a+mWLVs0cOBA+fr6ytvbW0888YRSU1P1yy+/qFevXipbtqz8/f01atQopaen24/PvhVz1qxZmjp1qqpVqyar1armzZvnWtP27dvVsWNHeXl5qUyZMgoLC9O6detyrWnjxo2KjIxUhQoVVKZMGUVFRWn06NGSpKCgIPvnGxcXJ+nPcbz33nvl7+8vDw8PhYSEaNy4cUpNTXU4/4ABA2Sz2XT8+HF17dpVNptNAQEBGjlypNLS0hzapqWlafLkyQoJCZHVapWvr686dOignTt32tsYhqEFCxaocePG8vDwULly5fTwww8rISEhX2MCAGZFeAMA3LbMzExlZGQ4bNmmTZumPn36qF69elq5cqXeffddXbp0Sffcc4+OHDlib3fq1CnVqVNHc+fO1YYNGzRz5kwlJSWpRYsWOnfunCSpW7dumjZtmiTpjTfe0K5du7Rr1y5169YtX3VHRUUpMTFR//jHP7R27VpVrFhR7733nu699155e3tr2bJlWrlypcqXL6+IiIh8BzhJevrpp+Xj46MVK1Zo/Pjx+uCDDzRw4EB169ZNjRo10qpVq9S/f3/NmTNH8+fPz3H866+/rvXr12vu3Ll67733VKpUKXXp0kW7du2yt/n666/1t7/9TcnJyVqyZIk+/PBDeXl5qXv37vroo49ynDMyMlKlS5fWu+++q1WrVum5557TCy+8IElavXq1/fNt2rSpJOnYsWPq2rWrlixZovXr12v48OFauXKlunfvnuPc6enpeuCBB9SxY0d98sknioyM1KuvvqqZM2fa22RkZKhLly6aMmWK7r//fq1Zs0ZLly5VWFiYEhMT7e2effZZDR8+XJ06ddK//vUvLViwQN9//73CwsL066+/5ntMAMB0DAAA8umdd94xJOW6paenG4mJiYarq6vxwgsvOBx36dIlo3LlykavXr3yPHdGRoZx+fJlw9PT05g3b559/z//+U9DkvHVV1/lOKZ69epG//79c+xv166d0a5dO/vrr776ypBktG3b1qFdamqqUb58eaN79+4O+zMzM41GjRoZLVu2vMGnYRgnT540JBmzZ8+278v+jK7/DHr06GFIMl555RWH/Y0bNzaaNm2a45xVqlQx/vjjD/v+lJQUo3z58kanTp3s++6++26jYsWKxqVLl+z7MjIyjAYNGhh33XWXkZWV5VDTE088kaMPs2fPNiQZJ0+evGFfs7KyjPT0dOPrr782JBmHDh2yv9e/f39DkrFy5UqHY7p27WrUqVPH/nr58uWGJGPRokV5XmfXrl2GJGPOnDkO+0+fPm14eHgYY8aMuWGdAFCcMPMGALhty5cv1969ex02V1dXbdiwQRkZGXriiSccZuWsVqvatWtnvx1Pki5fvqyxY8cqODhYrq6ucnV1lc1mU2pqquLj4wul7r///e8Or3fu3KkLFy6of//+DvVmZWXpvvvu0969e3PcIniz7r//fofXISEhkpRj1jAkJMThVtFsPXv2dHgmLXtGbevWrcrMzFRqaqr27Nmjhx9+WDabzd7OxcVF/fr1088//6yjR4/esP9/JSEhQX379lXlypXl4uKi0qVLq127dpKUY4wsFkuOGbmGDRs69O2LL76Q1WpVZGRkntf87LPPZLFY9PjjjzuMSeXKldWoUSOH/w0BQHFXMp/KBgAUqJCQkFwXLMm+pa1Fixa5Hleq1H//P8S+fftq8+bNiomJUYsWLeTt7S2LxaKuXbvqjz/+KJS6/f39c6334YcfzvOYCxcuyNPT85avVb58eYfXbm5uee6/evVqjuMrV66c675r167p8uXLunTpkgzDyNEn6b8rf54/f95hf25t83L58mXdc889slqteumll1S7dm2VKVNGp0+fVs+ePXOMUZkyZXIsgOLu7u7Qt7Nnz6pKlSoO/zu43q+//irDMFSpUqVc369Ro8ZN9wEAzI7wBgAoNH5+fpKkVatWqXr16nm2S05O1meffaaJEydq3Lhx9v1paWm6cOHCTV/ParXmWBBDks6dO2ev5X9ZLJZc650/f77uvvvuXK+RV4gobL/88kuu+9zc3GSz2eTq6qpSpUopKSkpR7szZ85IUo7P4Pr+38iWLVt05swZxcXF2WfbJN3W78FVqFBB27dvV1ZWVp4Bzs/PTxaLRdu2bZO7u3uO93PbBwDFFeENAFBoIiIi5OrqqhMnTtzwFj2LxSLDMHJ8EV+8eLEyMzMd9mW3yW02LjAwUN99953Dvh9//FFHjx7NNbxdLzw8XGXLltWRI0c0ZMiQv2x/J61evVqzZ8+2z2ZdunRJa9eu1T333CMXFxd5enqqVatWWr16tV5++WV5eHhIkrKysvTee+/prrvuUu3atf/yOnl9vtlB7/oxevPNN/Pdpy5duujDDz/U0qVL87x18v7779eMGTP0n//8R7169cr3tQCgOCC8AQAKTWBgoCZPnqzo6GglJCTovvvuU7ly5fTrr7/qm2++kaenp2JjY+Xt7a22bdtq9uzZ8vPzU2BgoL7++mstWbIkxw9FN2jQQJL01ltvycvLS1arVUFBQfL19VW/fv30+OOP6/nnn9ff//53/fTTT5o1a5YqVKhwU/XabDbNnz9f/fv314ULF/Twww+rYsWKOnv2rA4dOqSzZ89q4cKFBf0x3RQXFxd17txZI0aMUFZWlmbOnKmUlBTFxsba20yfPl2dO3dWhw4dNGrUKLm5uWnBggX697//rQ8//PCmZtpCQ0MlSfPmzVP//v1VunRp1alTR2FhYSpXrpwGDRqkiRMnqnTp0nr//fd16NChfPepT58+eueddzRo0CAdPXpUHTp0UFZWlvbs2aOQkBD17t1b4eHheuaZZ/Tkk09q3759atu2rTw9PZWUlKTt27crNDRUzz33XL5rAAAzYcESAEChioqK0qpVq/Tjjz+qf//+ioiI0JgxY/TTTz+pbdu29nYffPCBOnTooDFjxqhnz57at2+fvvzyS/n4+DicLygoSHPnztWhQ4fUvn17tWjRQmvXrpX053Nzs2bN0oYNG3T//fdr4cKFWrhw4U3NOGV7/PHH9dVXX+ny5ct69tln1alTJw0bNkzffvutOnbsWDAfSj4MGTJEnTt31tChQ9W3b19lZGRo3bp1Cg8Pt7dp166dtmzZIk9PTw0YMEC9e/dWcnKyPv30Uz366KM3dZ327dsrKipKa9euVZs2bdSiRQvt379fvr6+WrduncqUKaPHH39ckZGRstlsuf4Ewc1ydXXV559/rqioKK1Zs0YPPvignnjiCW3fvt3hNts333xTr7/+urZu3arevXurW7dumjBhglJTU9WyZct8Xx8AzMZiGIbh7CIAAEDuTp06paCgIM2ePVujRo1ydjkAACdi5g0AAAAATIDwBgAAAAAmwG2TAAAAAGACzLwBAAAAgAkQ3gAAAADABAhvAAAAAGAC/Ei3k2RlZenMmTPy8vK6qR9NBQAAAFA8GYahS5cuqUqVKipVKu/5NcKbk5w5c0YBAQHOLgMAAABAEXH69Gndddddeb5PeHMSLy8vSX8OkLe3t5OrAQAAAOAsKSkpCggIsGeEvBDenCT7Vklvb2/CGwAAAIC/fJyKBUsAAAAAwAQIbwAAAABgAoQ3AAAAADABwhsAAAAAmADhDQAAAABMgPAGAAAAACZAeAMAAAAAEyC8AQAAAIAJEN4AAAAAwAQIbwAAAABgAoQ3AAAAADABwhsAAAAAmADhDQAAAABMgPAGAAAAACZAeAMAAAAAEyC8AQAAAIAJEN4AAAAAwAQIbwAAAABgAq7OLqCke+XQeVlt15xdBgAAAFBijGvi5+wS8oWZNwAAAAAwAcIbAAAAAJgA4Q0AAAAATIDwBgAAAAAmQHgDAAAAABMgvAEAAACACRDeAAAAAMAECG8AAAAAYAKENwAAAAAwAcIbAAAAAJgA4S0PWVlZmjlzpoKDg+Xu7q5q1app6tSpkqSxY8eqdu3aKlOmjGrUqKGYmBilp6c7uWIAAAAAxZmrswsoqqKiorRo0SK9+uqratOmjZKSkvTDDz9Ikry8vLR06VJVqVJFhw8f1sCBA+Xl5aUxY8bkeb60tDSlpaXZX6ekpBR6HwAAAAAUHxbDMAxnF1HUXLp0SRUqVNDrr7+up59++i/bz549Wx999JH27duXZ5tJkyYpNjY2x/6JWxNktXndVr0AAAAAbt64Jn7OLsFBSkqKfHx8lJycLG9v7zzbcdtkLuLj45WWlqaOHTvm+v6qVavUpk0bVa5cWTabTTExMUpMTLzhOaOiopScnGzfTp8+XRilAwAAACimCG+58PDwyPO93bt3q3fv3urSpYs+++wzHThwQNHR0bp27doNz+nu7i5vb2+HDQAAAABuFuEtF7Vq1ZKHh4c2b96c470dO3aoevXqio6OVvPmzVWrVi399NNPTqgSAAAAQEnCgiW5sFqtGjt2rMaMGSM3NzeFh4fr7Nmz+v777xUcHKzExEStWLFCLVq00Lp167RmzRpnlwwAAACgmGPmLQ8xMTEaOXKkJkyYoJCQED366KP67bff9OCDD+rFF1/UkCFD1LhxY+3cuVMxMTHOLhcAAABAMcdqk06SvaIMq00CAAAAdxarTQIAAAAACg3hDQAAAABMgPAGAAAAACZAeAMAAAAAEyC8AQAAAIAJEN4AAAAAwAT4kW4nG9HI94bLgQIAAACAxMwbAAAAAJgC4Q0AAAAATIDwBgAAAAAmQHgDAAAAABMgvAEAAACACRDeAAAAAMAE+KkAJ3vl0HlZbdecXQYAAABQZIxr4ufsEookZt4AAAAAwAQIbwAAAABgAoQ3AAAAADABwhsAAAAAmADhDQAAAABMgPAGAAAAACZAeAMAAAAAEyjS4S0uLk4Wi0W///77bZ0nMDBQc+fOLZCaJKl9+/YaPnx4gZ0PAAAAAP5KkQpvhCIAAAAAyF2RCm8AAAAAgNwVmfA2YMAAff3115o3b54sFossFotOnTolSdq/f7+aN2+uMmXKKCwsTEePHrUfd+LECT344IOqVKmSbDabWrRooU2bNt3wWq+88opCQ0Pl6empgIAAPf/887p8+bJDmx07dqhdu3YqU6aMypUrp4iICF28eNH+flZWlsaMGaPy5curcuXKmjRpUoF9FgAAAABwvSIT3ubNm6fWrVtr4MCBSkpKUlJSkgICAiRJ0dHRmjNnjvbt2ydXV1dFRkbaj7t8+bK6du2qTZs26cCBA4qIiFD37t2VmJiY57VKlSql1157Tf/+97+1bNkybdmyRWPGjLG/f/DgQXXs2FH169fXrl27tH37dnXv3l2ZmZn2NsuWLZOnp6f27NmjWbNmafLkyfryyy/zvGZaWppSUlIcNgAAAAC4WRbDMAxnF5Gtffv2aty4sX1xkbi4OHXo0EGbNm1Sx44dJUmff/65unXrpj/++ENWqzXX89SvX1/PPfechgwZIunPBUuGDx+e5/N0//znP/Xcc8/p3LlzkqS+ffsqMTFR27dvz7POzMxMbdu2zb6vZcuW+tvf/qYZM2bkesykSZMUGxubY//ErQmy2rxyPQYAAAAoicY18XN2CXdUSkqKfHx8lJycLG9v7zzbFZmZtxtp2LCh/W9/f39J0m+//SZJSk1N1ZgxY1SvXj2VLVtWNptNP/zwww1n3r766it17txZVatWlZeXl5544gmdP39eqampkv4783azNWXXlV1TbqKiopScnGzfTp8+feNOAwAAAMD/MEV4K126tP1vi8Ui6c9nziRp9OjR+vjjjzV16lRt27ZNBw8eVGhoqK5du5bruX766Sd17dpVDRo00Mcff6z9+/frjTfekCSlp6dLkjw8PG6ppuy6smvKjbu7u7y9vR02AAAAALhZRSq8ubm5OTxXdjO2bdumAQMG6KGHHlJoaKgqV65sX+gkN/v27VNGRobmzJmju+++W7Vr19aZM2cc2jRs2FCbN2/OTxcAAAAAoFAUqfAWGBioPXv26NSpUzp37twNZ7KyBQcHa/Xq1Tp48KAOHTqkvn373vC4mjVrKiMjQ/Pnz1dCQoLeffdd/eMf/3BoExUVpb179+r555/Xd999px9++EELFy60PxMHAAAAAHdakQpvo0aNkouLi+rVq6cKFSrc8Lm1bK+++qrKlSunsLAwde/eXREREWratGme7Rs3bqxXXnlFM2fOVIMGDfT+++9r+vTpDm1q166tjRs36tChQ2rZsqVat26tTz75RK6urrfdRwAAAADIjyK12mRJkr2iDKtNAgAAAI5YbTJ3RWrmDQAAAACQO8IbAAAAAJgA4Q0AAAAATIDwBgAAAAAmQHgDAAAAABMgvAEAAACACfDDZU42opHvDZcDBQAAAACJmTcAAAAAMAXCGwAAAACYAOENAAAAAEyA8AYAAAAAJkB4AwAAAAATYLVJJ3vl0HlZbdecXQYAAEC+jGvi5+wSgBKDmTcAAAAAMAHCGwAAAACYAOENAAAAAEyA8AYAAAAAJkB4AwAAAAATILwBAAAAgAkQ3gAAAADABAhvAAAAAGAChDcAAAAAMAHCGwAAAACYAOENAAAAAEygRIa39evXq02bNipbtqx8fX11//3368SJE/b3d+7cqcaNG8tqtap58+b617/+JYvFooMHD9rbHDlyRF27dpXNZlOlSpXUr18/nTt3Ls9rpqWlKSUlxWEDAAAAgJtVIsNbamqqRowYob1792rz5s0qVaqUHnroIWVlZenSpUvq3r27QkND9e2332rKlCkaO3asw/FJSUlq166dGjdurH379mn9+vX69ddf1atXrzyvOX36dPn4+Ni3gICAwu4mAAAAgGLEYhiG4ewinO3s2bOqWLGiDh8+rO3bt2v8+PH6+eefZbVaJUmLFy/WwIEDdeDAATVu3FgTJkzQnj17tGHDBvs5fv75ZwUEBOjo0aOqXbt2jmukpaUpLS3N/jolJUUBAQGauDVBVptX4XcSAACgEIxr4ufsEgDTS0lJkY+Pj5KTk+Xt7Z1nO9c7WFORceLECcXExGj37t06d+6csrKyJEmJiYk6evSoGjZsaA9uktSyZUuH4/fv36+vvvpKNpst13PnFt7c3d3l7u5ewD0BAAAAUFKUyPDWvXt3BQQEaNGiRapSpYqysrLUoEEDXbt2TYZhyGKxOLS/fnIyKytL3bt318yZM3Oc29/fv1BrBwAAAFAylbjwdv78ecXHx+vNN9/UPffcI0navn27/f26devq/fffV1pamn2mbN++fQ7naNq0qT7++GMFBgbK1bXEfYQAAAAAnKDELVhSrlw5+fr66q233tLx48e1ZcsWjRgxwv5+3759lZWVpWeeeUbx8fHasGGDXn75ZUmyz8gNHjxYFy5cUJ8+ffTNN98oISFBGzduVGRkpDIzM53SLwAAAADFW4kLb6VKldKKFSu0f/9+NWjQQC+++KJmz55tf9/b21tr167VwYMH1bhxY0VHR2vChAmSZH8OrkqVKtqxY4cyMzMVERGhBg0aaNiwYfLx8VGpUiXuIwUAAABwB7Da5E14//339eSTTyo5OVkeHh4Fcs7sFWVYbRIAAJgZq00Ct4/VJm/D8uXLVaNGDVWtWlWHDh3S2LFj1atXrwILbgAAAABwqwhvufjll180YcIE/fLLL/L399cjjzyiqVOnOrssAAAAACUY4S0XY8aM0ZgxY5xdBgAAAADYsboGAAAAAJgA4Q0AAAAATIDwBgAAAAAmwDNvTjaike8NlwMFAAAAAImZNwAAAAAwBcIbAAAAAJgA4Q0AAAAATIDwBgAAAAAmQHgDAAAAABNgtUkne+XQeVlt15xdBgAAwE0Z18TP2SUAJRYzbwAAAABgAoQ3AAAAADABwhsAAAAAmADhDQAAAABMgPAGAAAAACZAeAMAAAAAEyC8AQAAAIAJEN4AAAAAwAQIbwAAAABgAoQ3AAAAADABwlsesrKyNHPmTAUHB8vd3V3VqlXT1KlTderUKVksFq1YsUJhYWGyWq2qX7++4uLinF0yAAAAgGLM1dkFFFVRUVFatGiRXn31VbVp00ZJSUn64Ycf7O+PHj1ac+fOVb169fTKK6/ogQce0MmTJ+Xr65vr+dLS0pSWlmZ/nZKSUuh9AAAAAFB8MPOWi0uXLmnevHmaNWuW+vfvr5o1a6pNmzZ6+umn7W2GDBmiv//97woJCdHChQvl4+OjJUuW5HnO6dOny8fHx74FBATcia4AAAAAKCYIb7mIj49XWlqaOnbsmGeb1q1b2/92dXVV8+bNFR8fn2f7qKgoJScn27fTp08XaM0AAAAAijdum8yFh4dHvo6zWCx5vufu7i53d/f8lgQAAACghGPmLRe1atWSh4eHNm/enGeb3bt32//OyMjQ/v37Vbdu3TtRHgAAAIASiJm3XFitVo0dO1ZjxoyRm5ubwsPDdfbsWX3//ff2WynfeOMN1apVSyEhIXr11Vd18eJFRUZGOrlyAAAAAMUV4S0PMTExcnV11YQJE3TmzBn5+/tr0KBB9vdnzJihmTNn6sCBA6pZs6Y++eQT+fn5ObFiAAAAAMUZ4S0PpUqVUnR0tKKjox32nzp1SpIUEhLicOskAAAAABQmnnkDAAAAABMgvAEAAACACXDb5C0KDAyUYRjOLgMAAABACcPMGwAAAACYAOENAAAAAEyA8AYAAAAAJsAzb042opGvvL29nV0GAAAAgCKOmTcAAAAAMAHCGwAAAACYAOENAAAAAEyA8AYAAAAAJkB4AwAAAAATILwBAAAAgAnwUwFO9sqh87Larjm7DAAAYALjmvg5uwQATsTMGwAAAACYAOENAAAAAEyA8AYAAAAAJkB4AwAAAAATILwBAAAAgAkQ3gAAAADABAhvAAAAAGACRTa8xcXFyWKx6Pfff8+zzdKlS1W2bNk7VlO2SZMmqXHjxnf8ugAAAABKriIb3gAAAAAA/0V4AwAAAAATcGp4S0tL09ChQ1WxYkVZrVa1adNGe/fuzbP90qVLVa1aNZUpU0YPPfSQzp8/7/B+9u2Mb775pgICAlSmTBk98sgjOW69fOeddxQSEiKr1aq6detqwYIFDu+PHTtWtWvXVpkyZVSjRg3FxMQoPT09z7pOnjyp4OBgPffcc8rKyrr1DwIAAAAA/oJTw9uYMWP08ccfa9myZfr2228VHBysiIgIXbhwIUfbPXv2KDIyUs8//7wOHjyoDh066KWXXsrR7vjx41q5cqXWrl2r9evX6+DBgxo8eLD9/UWLFik6OlpTp05VfHy8pk2bppiYGC1btszexsvLS0uXLtWRI0c0b948LVq0SK+++mquffj3v/+t8PBwPfLII1q4cKFKlcr9I01LS1NKSorDBgAAAAA3y2nhLTU1VQsXLtTs2bPVpUsX1atXT4sWLZKHh4eWLFmSo/28efMUERGhcePGqXbt2ho6dKgiIiJytLt69aqWLVumxo0bq23btpo/f75WrFihX375RZI0ZcoUzZkzRz179lRQUJB69uypF198UW+++ab9HOPHj1dYWJgCAwPVvXt3jRw5UitXrsxxrV27dqldu3YaMWKEpk+ffsP+Tp8+XT4+PvYtICDgVj8yAAAAACWY08LbiRMnlJ6ervDwcPu+0qVLq2XLloqPj8/RPj4+Xq1bt3bYd/1rSapWrZruuusuhzZZWVk6evSozp49q9OnT+upp56SzWazby+99JJOnDhhP2bVqlVq06aNKleuLJvNppiYGCUmJjpcJzExUZ06ddL48eM1atSov+xvVFSUkpOT7dvp06f/8hgAAAAAyObqrAsbhiFJslgsOfZfv+9/29+q7HNZLBb782iLFi1Sq1atHNq5uLhIknbv3q3evXsrNjZWERER8vHx0YoVKzRnzhyH9hUqVFCVKlW0YsUKPfXUU/L29r5hHe7u7nJ3d89XHwAAAADAaTNvwcHBcnNz0/bt2+370tPTtW/fPoWEhORoX69ePe3evdth3/WvpT9nxM6cOWN/vWvXLpUqVUq1a9dWpUqVVLVqVSUkJCg4ONhhCwoKkiTt2LFD1atXV3R0tJo3b65atWrpp59+ynEdDw8PffbZZ7JarYqIiNClS5fy/VkAAAAAwF9x2sybp6ennnvuOY0ePVrly5dXtWrVNGvWLF25ckVPPfWUDh065NB+6NChCgsL06xZs9SjRw9t3LhR69evz3Feq9Wq/v376+WXX1ZKSoqGDh2qXr16qXLlypL+XJFy6NCh8vb2VpcuXZSWlqZ9+/bp4sWLGjFihIKDg5WYmKgVK1aoRYsWWrdundasWZNnH9atW6cuXbqoS5cuWr9+vWw2W8F/WAAAAABKPKeuNjljxgz9/e9/V79+/dS0aVMdP35cGzZsULly5XK0vfvuu7V48WLNnz9fjRs31saNGzV+/Pgc7YKDg9WzZ0917dpV9957rxo0aODwUwBPP/20Fi9erKVLlyo0NFTt2rXT0qVL7TNvDz74oF588UUNGTJEjRs31s6dOxUTE5NnH2w2m7744gsZhqGuXbsqNTW1AD4ZAAAAAHBkMfL7MFkRNGnSJP3rX//SwYMHnV3KX0pJSZGPj48mbk2Q1ebl7HIAAIAJjGvi5+wSABSC7GyQnJx8w7U0nDrzBgAAAAC4OYQ3AAAAADCBYhXeJk2aZIpbJgEAAADgVhWr8AYAAAAAxRXhDQAAAABMgPAGAAAAACbgtB/pxp9GNPK94XKgAAAAACAx8wYAAAAApkB4AwAAAAATILwBAAAAgAkQ3gAAAADABAhvAAAAAGAChDcAAAAAMAF+KsDJXjl0XlbbNWeXAQAACtG4Jn7OLgFAMcDMGwAAAACYAOENAAAAAEyA8AYAAAAAJkB4AwAAAAATILwBAAAAgAkQ3gAAAADABAhvAAAAAGACJT68nTp1ShaLRQcPHryt8wQGBmru3LkFUhMAAAAAXK/EhzcAAAAAMAPCGwAAAACYQIkJb1lZWZo5c6aCg4Pl7u6uatWqaerUqfb3ExIS1KFDB5UpU0aNGjXSrl27HI7/+OOPVb9+fbm7uyswMFBz5sy5010AAAAAUIKVmPAWFRWlmTNnKiYmRkeOHNEHH3ygSpUq2d+Pjo7WqFGjdPDgQdWuXVt9+vRRRkaGJGn//v3q1auXevfurcOHD2vSpEmKiYnR0qVLb/r6aWlpSklJcdgAAAAA4Ga5OruAO+HSpUuaN2+eXn/9dfXv31+SVLNmTbVp00anTp2SJI0aNUrdunWTJMXGxqp+/fo6fvy46tatq1deeUUdO3ZUTEyMJKl27do6cuSIZs+erQEDBtxUDdOnT1dsbGyB9w0AAABAyVAiZt7i4+OVlpamjh075tmmYcOG9r/9/f0lSb/99pv9+PDwcIf24eHhOnbsmDIzM2+qhqioKCUnJ9u306dP32o3AAAAAJRgJWLmzcPD4y/blC5d2v63xWKR9OdzcpJkGIZ9XzbDMG6pBnd3d7m7u9/SMQAAAACQrUTMvNWqVUseHh7avHlzvo6vV6+etm/f7rBv586dql27tlxcXAqiRAAAAAC4oRIx82a1WjV27FiNGTNGbm5uCg8P19mzZ/X999/f8FbKbCNHjlSLFi00ZcoUPfroo9q1a5def/11LViw4A5UDwAAAAAlJLxJUkxMjFxdXTVhwgSdOXNG/v7+GjRo0E0d27RpU61cuVITJkzQlClT5O/vr8mTJ9/0YiUAAAAAcLssxq0+vIUCkZKSIh8fH03cmiCrzcvZ5QAAgEI0romfs0sAUIRlZ4Pk5GR5e3vn2a5EPPMGAAAAAGZHeAMAAAAAEyC8AQAAAIAJEN4AAAAAwATyHd7effddhYeHq0qVKvrpp58kSXPnztUnn3xSYMUBAAAAAP6Ur/C2cOFCjRgxQl27dtXvv/+uzMxMSVLZsmU1d+7cgqwPAAAAAKB8/lRAvXr1NG3aNPXo0UNeXl46dOiQatSooX//+99q3769zp07Vxi1Fis3uxwoAAAAgOKtUH8q4OTJk2rSpEmO/e7u7kpNTc3PKQEAAAAAN5Cv8BYUFKSDBw/m2P/FF1+oXr16t1sTAAAAAOA6rvk5aPTo0Ro8eLCuXr0qwzD0zTff6MMPP9T06dO1ePHigq4RAAAAAEq8fIW3J598UhkZGRozZoyuXLmivn37qmrVqpo3b5569+5d0DUCAAAAQIl3y+EtIyND77//vrp3766BAwfq3LlzysrKUsWKFQujPgAAAACA8vHMm6urq5577jmlpaVJkvz8/AhuAAAAAFDI8nXbZKtWrXTgwAFVr169oOspcV45dF5W2zVnlwEAQIkzromfs0sAgFuSr/D2/PPPa+TIkfr555/VrFkzeXp6OrzfsGHDAikOAAAAAPCnfIW3Rx99VJI0dOhQ+z6LxSLDMGSxWJSZmVkw1QEAAAAAJOUzvJ08ebKg6wAAAAAA3EC+whvPugEAAADAnZWv8LZ8+fIbvv/EE0/kqxgAAAAAQO7yFd6GDRvm8Do9PV1XrlyRm5ubypQpQ3gDAAAAgAJ2y7/zJkkXL1502C5fvqyjR4+qTZs2+vDDDwu6RgAAAAAo8fIV3nJTq1YtzZgxI8esXFEXFxcni8Wi33///bbOExgYqLlz5xZITQAAAABwvQILb5Lk4uKiM2fOFOQpC1z79u01fPhwZ5cBAAAAALckX8+8ffrppw6vDcNQUlKSXn/9dYWHhxdIYQAAAACA/8rXzFuPHj0ctp49e2rSpElq2LCh3n777YKuscAMGDBAX3/9tebNmyeLxSKLxaJTp05Jkvbv36/mzZurTJkyCgsL09GjR+3HnThxQg8++KAqVaokm82mFi1aaNOmTU7qBQAAAICSKF/hLSsry2HLzMzUL7/8og8++ED+/v4FXWOBmTdvnlq3bq2BAwcqKSlJSUlJCggIkCRFR0drzpw52rdvn1xdXRUZGWk/7vLly+ratas2bdqkAwcOKCIiQt27d1diYuJNXzstLU0pKSkOGwAAAADcrHyFt8mTJ+vKlSs59v/xxx+aPHnybRdVWHx8fOw/Z1C5cmVVrlxZLi4ukqSpU6eqXbt2qlevnsaNG6edO3fq6tWrkqRGjRrp2WefVWhoqGrVqqWXXnpJNWrUyHH76I1Mnz5dPj4+9i07NAIAAADAzchXeIuNjdXly5dz7L9y5YpiY2NvuyhnaNiwof3v7NnD3377TZKUmpqqMWPGqF69eipbtqxsNpt++OGHW5p5i4qKUnJysn07ffp0wXYAAAAAQLGWrwVLDMOQxWLJsf/QoUMqX778bRflDKVLl7b/nd23rKwsSdLo0aO1YcMGvfzyywoODpaHh4cefvhhXbt27abP7+7uLnd394ItGgAAAECJcUvhrVy5cvaFPmrXru0Q4DIzM3X58mUNGjSowIssSG5ubsrMzLylY7Zt26YBAwbooYcekvTnM3DZC50AAAAAwJ1wS+Ft7ty5MgxDkZGRio2NlY+Pj/09Nzc3BQYGqnXr1gVeZEEKDAzUnj17dOrUKdlsNvvs2o0EBwdr9erV6t69uywWi2JiYm7qOAAAAAAoKLcU3vr37y9JCgoKUlhYmMOthmYxatQo9e/fX/Xq1dMff/yhd9555y+PefXVVxUZGamwsDD5+flp7NixrBYJAAAA4I6yGIZh3M4J/vjjD6Wnpzvs8/b2vq2iSoKUlBT5+Pho4tYEWW1ezi4HAIASZ1wTP2eXAACS/psNkpOTb5il8rXa5JUrVzRkyBBVrFhRNptN5cqVc9gAAAAAAAUrX+Ft9OjR2rJlixYsWCB3d3ctXrxYsbGxqlKlipYvX17QNQIAAABAiZevnwpYu3atli9frvbt2ysyMlL33HOPgoODVb16db3//vt67LHHCrpOAAAAACjR8jXzduHCBQUFBUn68/m2CxcuSJLatGmjrVu3Flx1AAAAAABJ+QxvNWrUsP/OWb169bRy5UpJf87IlS1btqBqAwAAAAD8f/kKb08++aQOHTokSYqKirI/+/biiy9q9OjRBVogAAAAAKAAfipAkhITE7Vv3z7VrFlTjRo1Koi6ir2bXQ4UAAAAQPF2s9kgXwuW/K+rV6+qWrVqqlat2u2eCgAAAACQh3zdNpmZmakpU6aoatWqstlsSkhIkCTFxMRoyZIlBVogAAAAACCf4W3q1KlaunSpZs2aJTc3N/v+0NBQLV68uMCKAwAAAAD8KV/hbfny5Xrrrbf02GOPycXFxb6/YcOG+uGHHwqsOAAAAADAn/IV3v7zn/8oODg4x/6srCylp6ffdlEAAAAAAEf5WrCkfv362rZtm6pXr+6w/5///KeaNGlSIIWVFK8cOi+r7ZqzywAA3AHjmvg5uwQAgInlK7xNnDhR/fr103/+8x9lZWVp9erVOnr0qJYvX67PPvusoGsEAAAAgBLvlm6bTEhIkGEY6t69uz766CN9/vnnslgsmjBhguLj47V27Vp17ty5sGoFAAAAgBLrlmbeatWqpaSkJFWsWFERERF6++23dfz4cVWuXLmw6gMAAAAA6BZn3gzDcHj9xRdf6MqVKwVaEAAAAAAgp3ytNpnt+jAHAAAAACgctxTeLBaLLBZLjn0AAAAAgMJ1S8+8GYahAQMGyN3dXZJ09epVDRo0SJ6eng7tVq9eXXAVAgAAAABuLbz179/f4fXjjz9eoMUAAAAAAHJ3S+HtnXfeKaw6ioRTp04pKChIBw4cUOPGjZ1dDgAAAADY3daCJWY2YMAA9ejRw9llAAAAAMBNMW14u3btmrNLAAAAAIA7xjThrX379hoyZIhGjBghPz8/de7cWUeOHFHXrl1ls9lUqVIl9evXT+fOnbMfs2rVKoWGhsrDw0O+vr7q1KmTUlNTNWnSJC1btkyffPKJfQXNuLg4+3E//PCDwsLCZLVaVb9+fYf34uLiZLFYtG7dOjVq1EhWq1WtWrXS4cOH7+CnAQAAAKCkMU14k6Rly5bJ1dVVO3bs0IwZM9SuXTs1btxY+/bt0/r16/Xrr7+qV69ekqSkpCT16dNHkZGRio+PV1xcnHr27CnDMDRq1Cj16tVL9913n5KSkpSUlKSwsDD7dUaPHq2RI0fqwIEDCgsL0wMPPKDz58871DJ69Gi9/PLL2rt3rypWrKgHHnhA6enpedaelpamlJQUhw0AAAAAbtYtLVjibMHBwZo1a5YkacKECWratKmmTZtmf//tt99WQECAfvzxR12+fFkZGRnq2bOnqlevLkkKDQ21t/Xw8FBaWpoqV66c4zpDhgzR3//+d0nSwoULtX79ei1ZskRjxoyxt5k4caI6d+4s6c9Qedddd2nNmjX28Hi96dOnKzY29jY/AQAAAAAllalm3po3b27/e//+/frqq69ks9nsW926dSVJJ06cUKNGjdSxY0eFhobqkUce0aJFi3Tx4sWbuk7r1q3tf7u6uqp58+aKj4/Ps0358uVVp06dHG3+V1RUlJKTk+3b6dOnb6oWAAAAAJBMNvP2vz8GnpWVpe7du2vmzJk52vn7+8vFxUVffvmldu7cqY0bN2r+/PmKjo7Wnj17FBQUdMvXtlgst9XG3d3d/uPmAAAAAHCrTDXz9r+aNm2q77//XoGBgQoODnbYskOexWJReHi4YmNjdeDAAbm5uWnNmjWSJDc3N2VmZuZ67t27d9v/zsjI0P79++2zerm1uXjxon788cccbQAAAACgoJg2vA0ePFgXLlxQnz599M033yghIUEbN25UZGSkMjMztWfPHk2bNk379u1TYmKiVq9erbNnzyokJESSFBgYqO+++05Hjx7VuXPnHBYbeeONN7RmzRr98MMPGjx4sC5evKjIyEiH60+ePFmbN2/Wv//9bw0YMEB+fn78bhwAAACAQmPa8FalShXt2LFDmZmZioiIUIMGDTRs2DD5+PioVKlS8vb21tatW9W1a1fVrl1b48eP15w5c9SlSxdJ0sCBA1WnTh01b95cFSpU0I4dO+znnjFjhmbOnKlGjRpp27Zt+uSTT+Tn5+dw/RkzZmjYsGFq1qyZkpKS9Omnn8rNze2OfgYAAAAASg6LYRiGs4swk7i4OHXo0EEXL15U2bJl832elJQU+fj4aOLWBFltXgVXIACgyBrXxO+vGwEASpzsbJCcnCxvb+8825l25g0AAAAAShLCGwAAAACYgKl+KqAoaN++vbjTFAAAAMCdxswbAAAAAJgA4Q0AAAAATIDwBgAAAAAmwDNvTjaike8NlwMFAAAAAImZNwAAAAAwBcIbAAAAAJgA4Q0AAAAATIDwBgAAAAAmQHgDAAAAABNgtUkne+XQeVlt15xdBlCsjGvi5+wSAAAAChwzbwAAAABgAoQ3AAAAADABwhsAAAAAmADhDQAAAABMgPAGAAAAACZAeAMAAAAAEyC8AQAAAIAJEN4AAAAAwAQIbwAAAABgAoQ3AAAAADAB04U3wzA0a9Ys1ahRQx4eHmrUqJFWrVolwzDUqVMn3XfffTIMQ5L0+++/q1q1aoqOjpYkZWZm6qmnnlJQUJA8PDxUp04dzZs3z+H8AwYMUI8ePfTyyy/L399fvr6+Gjx4sNLT0+1tkpKS1K1bN3l4eCgoKEgffPCBAgMDNXfu3Dv2OQAAAAAoWVydXcCtGj9+vFavXq2FCxeqVq1a2rp1qx5//HFVqFBBy5YtU2hoqF577TUNGzZMgwYNUqVKlTRp0iRJUlZWlu666y6tXLlSfn5+2rlzp5555hn5+/urV69e9mt89dVX8vf311dffaXjx4/r0UcfVePGjTVw4EBJ0hNPPKFz584pLi5OpUuX1ogRI/Tbb7/dsO60tDSlpaXZX6ekpBT8hwMAAACg2DJVeEtNTdUrr7yiLVu2qHXr1pKkGjVqaPv27XrzzTf1wQcf6M0331S/fv3066+/au3atTpw4IBKly4tSSpdurRiY2Pt5wsKCtLOnTu1cuVKh/BWrlw5vf7663JxcVHdunXVrVs3bd68WQMHDtQPP/ygTZs2ae/evWrevLkkafHixapVq9YNa58+fbrDtQEAAADgVpgqvB05ckRXr15V586dHfZfu3ZNTZo0kSQ98sgjWrNmjaZPn66FCxeqdu3aDm3/8Y9/aPHixfrpp5/0xx9/6Nq1a2rcuLFDm/r168vFxcX+2t/fX4cPH5YkHT16VK6urmratKn9/eDgYJUrV+6GtUdFRWnEiBH21ykpKQoICLj5zgMAAAAo0UwV3rKysiRJ69atU9WqVR3ec3d3lyRduXJF+/fvl4uLi44dO+bQZuXKlXrxxRc1Z84ctW7dWl5eXpo9e7b27Nnj0C57pi6bxWKxXzv7ebrr5bX/f+vLrhEAAAAAbpWpwlu9evXk7u6uxMREtWvXLtc2I0eOVKlSpfTFF1+oa9eu6tatm/72t79JkrZt26awsDA9//zz9vYnTpy4pRrq1q2rjIwMHThwQM2aNZMkHT9+XL///nv+OgUAAAAAN8FU4c3Ly0ujRo3Siy++qKysLLVp00YpKSnauXOnbDab/Pz89Pbbb2vXrl1q2rSpxo0bp/79++u7775TuXLlFBwcrOXLl2vDhg0KCgrSu+++q7179yooKOima6hbt646deqkZ555RgsXLlTp0qU1cuRIeXh4yGKxFGLvAQAAAJRkpvupgClTpmjChAmaPn26QkJCFBERobVr1yowMFBPPfWUJk2aZH8ebeLEiapSpYoGDRokSRo0aJB69uypRx99VK1atdL58+cdZuFu1vLly1WpUiW1bdtWDz30kAYOHCgvLy9ZrdYC7SsAAAAAZLMYf/WwFv7Szz//rICAAG3atEkdO3a8qWNSUlLk4+OjiVsTZLV5FXKFQMkyromfs0sAAAC4adnZIDk5Wd7e3nm2M9Vtk0XFli1bdPnyZYWGhiopKUljxoxRYGCg2rZt6+zSAAAAABRThLd8SE9P1//93/8pISFBXl5eCgsL0/vvv59jlUoAAAAAKCiEt3yIiIhQRESEs8sAAAAAUIKYbsESAAAAACiJCG8AAAAAYAKENwAAAAAwAZ55c7IRjXxvuBwoAAAAAEjMvAEAAACAKRDeAAAAAMAECG8AAAAAYAKENwAAAAAwAcIbAAAAAJgA4Q0AAAAATICfCnCyVw6dl9V2zdllAPk2romfs0sAAAAoEZh5AwAAAAATILwBAAAAgAkQ3gAAAADABAhvAAAAAGAChDcAAAAAMAHCGwAAAACYAOENAAAAAEyA8AYAAAAAJkB4AwAAAAATILwBAAAAgAmU6PC2atUqhYaGysPDQ76+vurUqZNSU1MlSe+8845CQkJktVpVt25dLViwwH5cZGSkGjZsqLS0NElSenq6mjVrpscee8wp/QAAAABQ/JXY8JaUlKQ+ffooMjJS8fHxiouLU8+ePWUYhhYtWqTo6GhNnTpV8fHxmjZtmmJiYrRs2TJJ0muvvabU1FSNGzdOkhQTE6Nz5845BLzrpaWlKSUlxWEDAAAAgJvl6uwCnCUpKUkZGRnq2bOnqlevLkkKDQ2VJE2ZMkVz5sxRz549JUlBQUE6cuSI3nzzTfXv3182m03vvfee2rVrJy8vL82ZM0ebN2+Wj49PntebPn26YmNjC79jAAAAAIoli2EYhrOLcIbMzExFRETom2++UUREhO699149/PDDysjIUMWKFeXh4aFSpf47MZmRkSEfHx/9+uuv9n3/93//p+nTp2vs2LGaMWPGDa+XlpZmv81SklJSUhQQEKCJWxNktXkVfAeBO2RcEz9nlwAAAGBqKSkp8vHxUXJysry9vfNsV2Jn3lxcXPTll19q586d2rhxo+bPn6/o6GitXbtWkrRo0SK1atUqxzHZsrKytGPHDrm4uOjYsWN/eT13d3e5u7sXbCcAAAAAlBgl9pk3SbJYLAoPD1dsbKwOHDggNzc37dixQ1WrVlVCQoKCg4MdtqCgIPuxs2fPVnx8vL7++mtt2LBB77zzjhN7AgAAAKC4K7Ezb3v27NHmzZt17733qmLFitqzZ4/Onj2rkJAQTZo0SUOHDpW3t7e6dOmitLQ07du3TxcvXtSIESN08OBBTZgwQatWrVJ4eLjmzZunYcOGqV27dqpRo4azuwYAAACgGCqx4c3b21tbt27V3LlzlZKSourVq2vOnDnq0qWLJKlMmTKaPXu2xowZI09PT4WGhmr48OG6evWqHnvsMQ0YMEDdu3eXJD311FNat26d+vXrp61btzrcXgkAAAAABaHELljibNkPJbJgCcyOBUsAAABuz80uWFKin3kDAAAAALMgvAEAAACACRDeAAAAAMAECG8AAAAAYAKENwAAAAAwAcIbAAAAAJhAif2dt6JiRCPfGy4HCgAAAAASM28AAAAAYAqENwAAAAAwAcIbAAAAAJgA4Q0AAAAATIDwBgAAAAAmQHgDAAAAABPgpwKc7JVD52W1XXN2GSjmxjXxc3YJAAAAuE3MvAEAAACACRDeAAAAAMAECG8AAAAAYAKENwAAAAAwAcIbAAAAAJgA4Q0AAAAATIDwBgAAAAAmUOzD24ABA9SjRw9nlwEAAAAAt6XYhzcAAAAAKA4IbwAAAABgAsUmvK1atUqhoaHy8PCQr6+vOnXqpNTU1Bzt0tLSNHToUFWsWFFWq1Vt2rTR3r177e/HxcXJYrFo3bp1atSokaxWq1q1aqXDhw87nGfnzp1q27atPDw8FBAQoKFDh+Z6PQAAAAAoCMUivCUlJalPnz6KjIxUfHy84uLi1LNnTxmGkaPtmDFj9PHHH2vZsmX69ttvFRwcrIiICF24cMGh3ejRo/Xyyy9r7969qlixoh544AGlp6dLkg4fPqyIiAj17NlT3333nT766CNt375dQ4YMybPGtLQ0paSkOGwAAAAAcLOKTXjLyMhQz549FRgYqNDQUD3//POy2WwO7VJTU7Vw4ULNnj1bXbp0Ub169bRo0SJ5eHhoyZIlDm0nTpyozp07KzQ0VMuWLdOvv/6qNWvWSJJmz56tvn37avjw4apVq5bCwsL02muvafny5bp69WquNU6fPl0+Pj72LSAgoHA+DAAAAADFUrEIb40aNVLHjh0VGhqqRx55RIsWLdLFixdztDtx4oTS09MVHh5u31e6dGm1bNlS8fHxDm1bt25t/7t8+fKqU6eOvc3+/fu1dOlS2Ww2+xYREaGsrCydPHky1xqjoqKUnJxs306fPl0QXQcAAABQQrg6u4CC4OLioi+//FI7d+7Uxo0bNX/+fEVHR2vPnj0O7bJvo7RYLDn2X78vN9ltsrKy9Oyzz2ro0KE52lSrVi3XY93d3eXu7n5T/QEAAACA6xWLmTfpz2AVHh6u2NhYHThwQG5ubvbbHLMFBwfLzc1N27dvt+9LT0/Xvn37FBIS4tB29+7d9r8vXryoH3/8UXXr1pUkNW3aVN9//72Cg4NzbG5uboXYSwAAAAAlVbGYeduzZ482b96se++9VxUrVtSePXt09uxZhYSE6LvvvrO38/T01HPPPafRo0erfPnyqlatmmbNmqUrV67oqaeecjjn5MmT5evrq0qVKik6Olp+fn72H/seO3as7r77bg0ePFgDBw6Up6en4uPj9eWXX2r+/Pl3susAAAAASohiEd68vb21detWzZ07VykpKapevbrmzJmjLl266KOPPnJoO2PGDGVlZalfv366dOmSmjdvrg0bNqhcuXI52g0bNkzHjh1To0aN9Omnn9pn1Ro2bKivv/5a0dHRuueee2QYhmrWrKlHH330jvUZAAAAQMliMXJbT78Ei4uLU4cOHXTx4kWVLVu20K6TkpIiHx8fTdyaIKvNq9CuA0jSuCZ+zi4BAAAAecjOBsnJyfL29s6zXbF55g0AAAAAijPCGwAAAACYQLF45q0gtW/fXtxJCgAAAKCoYeYNAAAAAEyA8AYAAAAAJkB4AwAAAAAT4Jk3JxvRyPeGy4ECAAAAgMTMGwAAAACYAuENAAAAAEyA8AYAAAAAJkB4AwAAAAATILwBAAAAgAkQ3gAAAADABPipACd75dB5WW3XnF1GsTOuiZ+zSwAAAAAKFDNvAAAAAGAChDcAAAAAMAHCGwAAAACYAOENAAAAAEyA8AYAAAAAJkB4AwAAAAATILwBAAAAgAkQ3gAAAADABIp1eBswYIB69Ojh7DIAAAAA4LYV6fB27do1Z5cAAAAAAEVCkQpv7du315AhQzRixAj5+fmpc+fOOnLkiLp27SqbzaZKlSqpX79+OnfunP2YVatWKTQ0VB4eHvL19VWnTp2UmpqqSZMmadmyZfrkk09ksVhksVgUFxcnSfrPf/6jRx99VOXKlZOvr68efPBBnTp1yqGWt99+W/Xr15e7u7v8/f01ZMgQ+3s//PCD2rRpI6vVqnr16mnTpk2yWCz617/+dQc+JQAAAAAlUZEKb5K0bNkyubq6aseOHZoxY4batWunxo0ba9++fVq/fr1+/fVX9erVS5KUlJSkPn36KDIyUvHx8YqLi1PPnj1lGIZGjRqlXr166b777lNSUpKSkpIUFhamK1euqEOHDrLZbNq6dau2b98um82m++67zz7Tt3DhQg0ePFjPPPOMDh8+rE8//VTBwcGSpKysLPXo0UNlypTRnj179NZbbyk6Ovov+5WWlqaUlBSHDQAAAABulquzC7hecHCwZs2aJUmaMGGCmjZtqmnTptnff/vttxUQEKAff/xRly9fVkZGhnr27Knq1atLkkJDQ+1tPTw8lJaWpsqVK9v3vffeeypVqpQWL14si8UiSXrnnXdUtmxZxcXF6d5779VLL72kkSNHatiwYfbjWrRoIUnauHGjTpw4obi4OPt5p06dqs6dO9+wX9OnT1dsbOztfDQAAAAASrAiN/PWvHlz+9/79+/XV199JZvNZt/q1q0rSTpx4oQaNWqkjh07KjQ0VI888ogWLVqkixcv3vD8+/fv1/Hjx+Xl5WU/Z/ny5XX16lWdOHFCv/32m86cOaOOHTvmevzRo0cVEBDgEAhbtmz5l/2KiopScnKyfTt9+vTNfBwAAAAAIKkIzrx5enra/87KylL37t01c+bMHO38/f3l4uKiL7/8Ujt37tTGjRs1f/58RUdHa8+ePQoKCsr1/FlZWWrWrJnef//9HO9VqFBBpUrdOM8ahmGfsbsV7u7ucnd3v+XjAAAAAEAqgjNv/6tp06b6/vvvFRgYqODgYIctO+RZLBaFh4crNjZWBw4ckJubm9asWSNJcnNzU2ZmZo5zHjt2TBUrVsxxTh8fH3l5eSkwMFCbN2/Otaa6desqMTFRv/76q33f3r17C+kTAAAAAIA/FenwNnjwYF24cEF9+vTRN998o4SEBG3cuFGRkZHKzMzUnj17NG3aNO3bt0+JiYlavXq1zp49q5CQEElSYGCgvvvuOx09elTnzp1Tenq6HnvsMfn5+enBBx/Utm3bdPLkSX399dcaNmyYfv75Z0nSpEmTNGfOHL322ms6duyYvv32W82fP1+S1LlzZ9WsWVP9+/fXd999px07dtgXLMnPjBwAAAAA3IwiHd6qVKmiHTt2KDMzUxEREWrQoIGGDRsmHx8flSpVSt7e3tq6dau6du2q2rVra/z48ZozZ466dOkiSRo4cKDq1Kmj5s2bq0KFCtqxY4fKlCmjrVu3qlq1aurZs6dCQkIUGRmpP/74Q97e3pKk/v37a+7cuVqwYIHq16+v+++/X8eOHZMkubi46F//+pcuX76sFi1a6Omnn9b48eMlSVar1TkfFAAAAIBiz2IYhuHsIsxux44datOmjY4fP66aNWve1DEpKSny8fHRxK0Jstq8CrnCkmdcEz9nlwAAAADclOxskJycbJ9Qyk2RW7DEDNasWSObzaZatWrp+PHjGjZsmMLDw286uAEAAADArSK85cOlS5c0ZswYnT59Wn5+furUqZPmzJnj7LIAAAAAFGOEt3x44okn9MQTTzi7DAAAAAAlSJFesAQAAAAA8CfCGwAAAACYAOENAAAAAEyAZ96cbEQj3xsuBwoAAAAAEjNvAAAAAGAKhDcAAAAAMAHCGwAAAACYAOENAAAAAEyA8AYAAAAAJsBqk072yqHzstquObuMImVcEz9nlwAAAAAUOcy8AQAAAIAJEN4AAAAAwAQIbwAAAABgAoQ3AAAAADABwhsAAAAAmADhDQAAAABMgPAGAAAAACZAeAMAAAAAEyC8STIMQ88884zKly8vi8WismXLavjw4c4uCwAAAADsCG+S1q9fr6VLl+qzzz5TUlKSGjRo4OySAAAAAMCBq7MLKApOnDghf39/hYWFSZJcXflYAAAAABQtJX7mbcCAAXrhhReUmJgoi8WiwMBASVJGRoaGDBmismXLytfXV+PHj5dhGPbjFixYoFq1aslqtapSpUp6+OGHndQDAAAAACVBiQ9v8+bN0+TJk3XXXXcpKSlJe/fulSQtW7ZMrq6u2rNnj1577TW9+uqrWrx4sSRp3759Gjp0qCZPnqyjR49q/fr1atu27Q2vk5aWppSUFIcNAAAAAG5Wib8/0MfHR15eXnJxcVHlypXt+wMCAvTqq6/KYrGoTp06Onz4sF599VUNHDhQiYmJ8vT01P333y8vLy9Vr15dTZo0ueF1pk+frtjY2MLuDgAAAIBiqsTPvOXl7rvvlsVisb9u3bq1jh07pszMTHXu3FnVq1dXjRo11K9fP73//vu6cuXKDc8XFRWl5ORk+3b69OnC7gIAAACAYoTwlg9eXl769ttv9eGHH8rf318TJkxQo0aN9Pvvv+d5jLu7u7y9vR02AAAAALhZhLc87N69O8frWrVqycXFRdKfK1J26tRJs2bN0nfffadTp05py5YtzigVAAAAQAlQ4p95y8vp06c1YsQIPfvss/r22281f/58zZkzR5L02WefKSEhQW3btlW5cuX0+eefKysrS3Xq1HFy1QAAAACKK8JbHp544gn98ccfatmypVxcXPTCCy/omWeekSSVLVtWq1ev1qRJk3T16lXVqlVLH374oerXr+/kqgEAAAAUVxbjf3+8DHdMSkqKfHx8NHFrgqw2L2eXU6SMa+Ln7BIAAACAOyY7GyQnJ99wbQyeeQMAAAAAEyC8AQAAAIAJEN4AAAAAwAQIbwAAAABgAoQ3AAAAADABwhsAAAAAmAC/8+ZkIxr53nA5UAAAAACQmHkDAAAAAFMgvAEAAACACRDeAAAAAMAECG8AAAAAYAKENwAAAAAwAcIbAAAAAJgA4Q0AAAAATIDwBgAAAAAmQHgDAAAAABMgvAEAAACACRDeAAAAAMAECG8AAAAAYAKENwAAAAAwAcIbAAAAAJgA4Q0AAAAATIDwBgAAAAAmQHgDAAAAABMgvAEAAACACRDeAAAAAMAEXJ1dQEllGIYkKSUlxcmVAAAAAHCm7EyQnRHyQnhzkvPnz0uSAgICnFwJAAAAgKLg0qVL8vHxyfN9wpuTlC9fXpKUmJh4wwHCnZeSkqKAgACdPn1a3t7ezi4H12F8ijbGp+hibIo2xqdoY3yKruIyNoZh6NKlS6pSpcoN2xHenKRUqT8fN/Tx8TH1/9CKM29vb8amCGN8ijbGp+hibIo2xqdoY3yKruIwNjczocOCJQAAAABgAoQ3AAAAADABwpuTuLu7a+LEiXJ3d3d2KbgOY1O0MT5FG+NTdDE2RRvjU7QxPkVXSRsbi/FX61ECAAAAAJyOmTcAAAAAMAHCGwAAAACYAOENAAAAAEyA8AYAAAAAJkB4KyALFixQUFCQrFarmjVrpm3btt2w/ddff61mzZrJarWqRo0a+sc//pGjzccff6x69erJ3d1d9erV05o1awqr/GKvoMdn0aJFuueee1SuXDmVK1dOnTp10jfffFOYXSi2CuOfnWwrVqyQxWJRjx49CrjqkqMwxuf333/X4MGD5e/vL6vVqpCQEH3++eeF1YVirTDGZ+7cuapTp448PDwUEBCgF198UVevXi2sLhRbtzI2SUlJ6tu3r+rUqaNSpUpp+PDhubbje0HBKejx4XtBwSqMf36ymf67gYHbtmLFCqN06dLGokWLjCNHjhjDhg0zPD09jZ9++inX9gkJCUaZMmWMYcOGGUeOHDEWLVpklC5d2li1apW9zc6dOw0XFxdj2rRpRnx8vDFt2jTD1dXV2L17953qVrFRGOPTt29f44033jAOHDhgxMfHG08++aTh4+Nj/Pzzz3eqW8VCYYxNtlOnThlVq1Y17rnnHuPBBx8s5J4UT4UxPmlpaUbz5s2Nrl27Gtu3bzdOnTplbNu2zTh48OCd6laxURjj89577xnu7u7G+++/b5w8edLYsGGD4e/vbwwfPvxOdatYuNWxOXnypDF06FBj2bJlRuPGjY1hw4blaMP3goJTGOPD94KCUxjjk604fDcgvBWAli1bGoMGDXLYV7duXWPcuHG5th8zZoxRt25dh33PPvuscffdd9tf9+rVy7jvvvsc2kRERBi9e/cuoKpLjsIYn+tlZGQYXl5exrJly26/4BKksMYmIyPDCA8PNxYvXmz079/ftP+CdrbCGJ+FCxcaNWrUMK5du1bwBZcwhTE+gwcPNv72t785tBkxYoTRpk2bAqq6ZLjVsflf7dq1y/XLJ98LCk5hjM/1+F6Qf4U1PsXluwG3Td6ma9euaf/+/br33nsd9t97773auXNnrsfs2rUrR/uIiAjt27dP6enpN2yT1zmRu8Ian+tduXJF6enpKl++fMEUXgIU5thMnjxZFSpU0FNPPVXwhZcQhTU+n376qVq3bq3BgwerUqVKatCggaZNm6bMzMzC6UgxVVjj06ZNG+3fv99+u1dCQoI+//xzdevWrRB6UTzlZ2xuBt8LCkZhjc/1+F6QP4U5PsXlu4Grswswu3PnzikzM1OVKlVy2F+pUiX98ssvuR7zyy+/5No+IyND586dk7+/f55t8joncldY43O9cePGqWrVqurUqVPBFV/MFdbY7NixQ0uWLNHBgwcLq/QSobDGJyEhQVu2bNFjjz2mzz//XMeOHdPgwYOVkZGhCRMmFFp/ipvCGp/evXvr7NmzatOmjQzDUEZGhp577jmNGzeu0PpS3ORnbG4G3wsKRmGNz/X4XpA/hTU+xem7AeGtgFgsFofXhmHk2PdX7a/ff6vnRN4KY3yyzZo1Sx9++KHi4uJktVoLoNqSpSDH5tKlS3r88ce1aNEi+fn5FXyxJVBB/7OTlZWlihUr6q233pKLi4uaNWumM2fOaPbs2YS3fCjo8YmLi9PUqVO1YMECtWrVSsePH9ewYcPk7++vmJiYAq6+eCuM/4bzvaDgFOZnyfeC21eQ41PcvhsQ3m6Tn5+fXFxccvy/Ab/99luO/9cgW+XKlXNt7+rqKl9f3xu2yeucyF1hjU+2l19+WdOmTdOmTZvUsGHDgi2+mCuMsfn+++916tQpde/e3f5+VlaWJMnV1VVHjx5VzZo1C7gnxVNh/bPj7++v0qVLy8XFxd4mJCREv/zyi65duyY3N7cC7knxVFjjExMTo379+unpp5+WJIWGhio1NVXPPPOMoqOjVaoUT1v8lfyMzc3ge0HBKKzxycb3gttTGONz4sSJYvXdgH8L3yY3Nzc1a9ZMX375pcP+L7/8UmFhYbke07p16xztN27cqObNm6t06dI3bJPXOZG7whofSZo9e7amTJmi9evXq3nz5gVffDFXGGNTt25dHT58WAcPHrRvDzzwgDp06KCDBw8qICCg0PpT3BTWPzvh4eE6fvy4/T+ckvTjjz/K39+f4HYLCmt8rly5kiOgubi4yPhzgbMC7EHxlZ+xuRl8LygYhTU+Et8LCkJhjE+x+25wp1dIKY6ylzRdsmSJceTIEWP48OGGp6encerUKcMwDGPcuHFGv3797O2zl2t+8cUXjSNHjhhLlizJsVzzjh07DBcXF2PGjBlGfHy8MWPGDJYEzqfCGJ+ZM2cabm5uxqpVq4ykpCT7dunSpTvePzMrjLG5nplXlHK2whifxMREw2azGUOGDDGOHj1qfPbZZ0bFihWNl1566Y73z+wKY3wmTpxoeHl5GR9++KGRkJBgbNy40ahZs6bRq1evO94/M7vVsTEMwzhw4IBx4MABo1mzZkbfvn2NAwcOGN9//739fb4XFJzCGB++FxScwhif65n5uwHhrYC88cYbRvXq1Q03NzejadOmxtdff21/r3///ka7du0c2sfFxRlNmjQx3NzcjMDAQGPhwoU5zvnPf/7TqFOnjlG6dGmjbt26xscff1zY3Si2Cnp8qlevbkjKsU2cOPEO9KZ4KYx/dv6Xmf8FXRQUxvjs3LnTaNWqleHu7m7UqFHDmDp1qpGRkVHYXSmWCnp80tPTjUmTJhk1a9Y0rFarERAQYDz//PPGxYsX70BvipdbHZvc/ptSvXp1hzZ8Lyg4BT0+fC8oWIXxz8//MvN3A4thcB8EAAAAABR1PPMGAAAAACZAeAMAAAAAEyC8AQAAAIAJEN4AAAAAwAQIbwAAAABgAoQ3AAAAADABwhsAAAAAmADhDQAAAABMgPAGAAAAACZAeAMAlAgDBgxQjx49nF1Grk6dOiWLxaKDBw86uxQAQBFGeAMAwImuXbvm7BIAACZBeAMAlDjt27fXCy+8oOHDh6tcuXKqVKmS3nrrLaWmpurJJ5+Ul5eXatasqS+++MJ+TFxcnCwWi9atW6dGjRrJarWqVatWOnz4sMO5P/74Y9WvX1/u7u4KDAzUnDlzHN4PDAzUSy+9pAEDBsjHx0cDBw5UUFCQJKlJkyayWCxq3769JGnv3r3q3Lmz/Pz85OPjo3bt2unbb791OJ/FYtHixYv10EMPqUyZMqpVq5Y+/fRThzbff/+9unXrJm9vb3l5eemee+7RiRMn7O+/8847CgkJkdVqVd26dbVgwYLb/owBAAWP8AYAKJGWLVsmPz8/ffPNN3rhhRf03HPP6ZFHHlFYWJi+/fZbRUREqF+/frpy5YrDcaNHj9bLL7+svXv3qmLFinrggQeUnp4uSdq/f7969eql3r176/Dhw5o0aZJiYmK0dOlSh3PMnj1bDRo00P79+xUTE6NvvvlGkrRp0yYlJSVp9erVkqRLly6pf//+2rZtm3bv3q1atWqpa9euunTpksP5YmNj1atXL3333Xfq2rWrHnvsMV24cEGS9J///Edt27aV1WrVli1btH//fkVGRiojI0OStGjRIkVHR2vq1KmKj4/XtGnTFBMTo2XLlhX4Zw4AuE0GAAAlQP/+/Y0HH3zQMAzDaNeundGmTRv7exkZGYanp6fRr18/+76kpCRDkrFr1y7DMAzjq6++MiQZK1assLc5f/684eHhYXz00UeGYRhG3759jc6dOztcd/To0Ua9evXsr6tXr2706NHDoc3JkycNScaBAwdu2IeMjAzDy8vLWLt2rX2fJGP8+PH215cvXzYsFovxxRdfGIZhGFFRUUZQUJBx7dq1XM8ZEBBgfPDBBw77pkyZYrRu3fqGtQAA7jxm3gAAJVLDhg3tf7u4uMjX11ehoaH2fZUqVZIk/fbbbw7HtW7d2v53+fLlVadOHcXHx0uS4uPjFR4e7tA+PDxcx44dU2Zmpn1f8+bNb6rG3377TYMGDVLt2rXl4+MjHx8fXb58WYmJiXn2xdPTU15eXva6Dx48qHvuuUelS5fOcf6zZ8/q9OnTeuqpp2Sz2ezbSy+95HBbJQCgaHB1dgEAADjD9WHGYrE47LNYLJKkrKysvzxXdlvDMOx/ZzMMI0d7T0/Pm6pxwIABOnv2rObOnavq1avL3d1drVu3zrHISW59ya7bw8Mjz/Nnt1m0aJFatWrl8J6Li8tN1QgAuHMIbwAA3ILdu3erWrVqkqSLFy/qxx9/VN26dSVJ9erV0/bt2x3a79y5U7Vr175hGHJzc5Mkh9k5Sdq2bZsWLFigrl27SpJOnz6tc+fO3VK9DRs21LJly5Senp4j5FWqVElVq1ZVQkKCHnvssVs6LwDgziO8AQBwCyZPnixfX19VqlRJ0dHR8vPzs/9+3MiRI9WiRQtNmTJFjz76qHbt2qXXX3/9L1dvrFixojw8PLR+/Xrdddddslqt8vHxUXBwsN599101b95cKSkpGj169A1n0nIzZMgQzZ8/X71791ZUVJR8fHy0e/dutWzZUnXq1NGkSZM0dOhQeXt7q0uXLkpLS9O+fft08eJFjRgxIr8fEwCgEPDMGwAAt2DGjBkaNmyYmjVrpqSkJH366af2mbOmTZtq5cqVWrFihRo0aKAJEyZo8uTJGjBgwA3P6erqqtdee01vvvmmqlSpogcffFCS9Pbbb+vixYtq0qSJ+vXrp6FDh6pixYq3VK+vr6+2bNmiy5cvq127dmrWrJkWLVpkn4V7+umntXjxYi1dulShoaFq166dli5dav/5AgBA0WExcrsZHwAAOIiLi1OHDh108eJFlS1b1tnlAABKIGbeAAAAAMAECG8AAAAAYALcNgkAAAAAJsDMGwAAAACYAOENAAAAAEyA8AYAAAAAJkB4AwAAAAATILwBAAAAgAkQ3gAAAADABAhvAAAAAGAChDcAAAAAMIH/BzpBO5HTPxojAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame to hold feature names and their importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the features by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to show most important features at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312d0ac",
   "metadata": {},
   "source": [
    "#### Question: Which features stand out as the most influential?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecc6b9b",
   "metadata": {},
   "source": [
    "- ca: Number of major vessels (0-3) colored by fluoroscopy. Stand out as the most influential variable in predicting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929756b8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74afb733",
   "metadata": {},
   "source": [
    "### Optional Task 9: Dive into Gradient Boosted Regression Trees (GBRT)\n",
    "Explore the capabilities of Gradient Boosted Regression Trees and compare its performance with other models.\n",
    "- Implement a GBRT model using the training data. You can use the default parameters or experiment with settings like `n_estimators`, `learning_rate`, and `max_depth`.\n",
    "- Train the GBRT model using the training dataset.\n",
    "- Calculate and display the accuracy of the GBRT model on both the training and test datasets.\n",
    "- Compare the performance of the GBRT model with the single decision tree and the Random Forest model you previously trained. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a14292cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import related libraries\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Initializing GBRT classifier with default parameters and experimenting with specific parameters\n",
    "gbrt_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "531db0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the GBRT model using the training dataset.\n",
    "gbrt_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f61e564d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBRT Training Accuracy: 0.99\n",
      "GBRT Test Accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "train_predictions = gbrt_classifier.predict(X_train)\n",
    "test_predictions = gbrt_classifier.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"GBRT Training Accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"GBRT Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0a84e5",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "\n",
    "Training Accuracy:\n",
    "- The Random Forest model achieved the highest Training Accuracy (1.00), indicating that it perfectly fit the training data. This could be a sign of overfitting.\n",
    "- The GBRT model also performed very well on the training data with a Training Accuracy of 0.99, indicating a strong fit to the training data.\n",
    "- The single Decision Tree achieved a lower Training Accuracy of 0.85, which suggests it may have reduced overfitting compared to the Random Forest and GBRT models.\n",
    "\n",
    "Test Accuracy:\n",
    "- The Random Forest model achieved the highest Test Accuracy (0.87) among the three models, indicating better generalization to unseen data compared to its Training Accuracy.\n",
    "- The single Decision Tree and GBRT models had similar Test Accuracy scores (0.81 and 0.80, respectively). While the Decision Tree's Test Accuracy was slightly higher, the difference is not substantial.\n",
    "\n",
    "Overall Observation:\n",
    "\n",
    "- The Random Forest model appears to have the best balance between Training Accuracy and Test Accuracy, suggesting it generalizes well to unseen data while also fitting the training data effectively.\n",
    "- The GBRT model, despite having a high Training Accuracy, has a slightly lower Test Accuracy, indicating some degree of overfitting.\n",
    "- The single Decision Tree, with limited depth (max_depth=3), shows improved generalization compared to the default Decision Tree but still has a similar Test Accuracy to the GBRT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91edbade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10a01ebe",
   "metadata": {},
   "source": [
    "### Part 2: Starting Your ANA540 Machine Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f8c625",
   "metadata": {},
   "source": [
    "\n",
    "Here are the key considerations for your machine learning project:\n",
    "\n",
    "#### Define the Problem Statement:\n",
    "\n",
    "- What specific issue or question do you want to address with machine learning?\n",
    "- Is there a particular domain or industry you're interested in, such as healthcare, education, or social media?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696b9a15",
   "metadata": {},
   "source": [
    "#### Determine the Type of Machine Learning Problem:\n",
    "\n",
    "- **Classification**: Will you predict categories or labels? (e.g. spam vs not spam)\n",
    "- **Regression**: Will you forecast continuous numerical values? (e.g. housing prices)\n",
    "- **Clustering**: Will you group data based on similarities, without prior labels? (Covered Week 8)\n",
    "- **Dimensionality Reduction**: Will you reduce the number of features while retaining information? (e.g. PCA) (Covered Week 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d7c2af",
   "metadata": {},
   "source": [
    "#### Assess Data Sources\n",
    "\n",
    "- Do you have a specific dataset in mind? If not, where can you obtain relevant data?\n",
    "- Remember, the quality and quantity of data can significantly influence the project's outcomes.\n",
    "- Ensure you understand the features present in the dataset and what they represent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67e5cb2",
   "metadata": {},
   "source": [
    "#### Draft a Project Proposal Paragraph:\n",
    "Building on the considerations outlined above, craft a brief paragraph detailing your ANA540 project. This should clearly state the problem you aim to address, the type of machine learning technique you intend to use, and a brief overview of the data source(s) you'll be using (if you have already determined the dataset). \n",
    "\n",
    "This will serve as a starting point that we can refine further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc714f73",
   "metadata": {},
   "source": [
    "#### Project Proposal: Exploring the Future of Healthcare: Machine Learning-Powered Diabetes Risk Assessment\n",
    "\n",
    "##### 1. Introduction\n",
    "Diabetes is a prevalent and chronic health condition that impacts the lives of millions of individuals worldwide. Early detection and proactive intervention are paramount for effectively managing diabetes. Leveraging the capabilities of machine learning, this project aims to develop a predictive model for identifying individuals at risk of diabetes. The model will utilize a diverse set of health and demographic features to enable timely and informed intervention.\n",
    "\n",
    "##### 2. Problem Statement\n",
    "This project seeks to address the critical issue of diabetes prediction with the following objectives:\n",
    "- Prediction Accuracy: Develop a robust machine learning model capable of accurately predicting the likelihood of diabetes onset.\n",
    "- Early Intervention: Identify individuals at high risk of developing diabetes to facilitate early intervention, lifestyle adjustments, and improved health outcomes.\n",
    "- Data-Driven Insights: Gain valuable insights into the influential factors contributing to diabetes risk, promoting a deeper understanding of this complex health condition.\n",
    "\n",
    "##### 3. Machine Learning Technique\n",
    "To achieve these objectives, we will employ supervised machine learning, specifically focusing on classification algorithms. The model will be trained using historical health and demographic data to classify individuals into two categories: those at risk of developing diabetes (1) and those not at risk (0).\n",
    "\n",
    "##### 4. Data Source\n",
    "\n",
    "Our project will utilize a comprehensive dataset comprising an array of health-related variables, including:\n",
    "\n",
    "- Diabetes_prediction:\tDiabetes\t0 = no, 1 = yes\n",
    "- HighBP:\tHigh Blood Pressure\t0 = no, 1 = yes\n",
    "- HighChol:\tHigh Cholesterol\t0 = no high cholesterol, 1 = high cholesterol\n",
    "- CholCheck:\tCholesterol Check in 5 Years\t0 = no, 1 = yes\n",
    "- BMI:\tBody Mass Index\t\n",
    "- Smoker:\tHave you smoked at least 100 cigarettes in your life?\t0 = no, 1 = yes\n",
    "- Stroke:\t(Ever told) you had a stroke?\t0 = no, 1 = yes\n",
    "- HeartDiseaseorAttack:\tCoronary Heart Disease (CHD) or Myocardial Infarction (MI)\t0 = no, 1 = yes\n",
    "- PhysActivity:\tPhysical Activity in Past 30 Days (excluding job)\t0 = no, 1 = yes\n",
    "- Fruits:\tConsume Fruit 1 or more times per day\t0 = no, 1 = yes\n",
    "- Veggies:\tConsume Vegetables 1 or more times per day\t0 = no, 1 = yes\n",
    "- HvyAlcoholConsump:\tHeavy Alcohol Consumption\t0 = no, 1 = yes (for adult men >=14 drinks per week and adult women >=7 drinks per week)\n",
    "- AnyHealthcare:\tHave any kind of healthcare coverage, including health insurance, prepaid plans such as HMO, etc.\t0 = no, 1 = yes\n",
    "- NoDocbcCost:\tWas there a time in the past 12 months when you needed to see a doctor but could not because of cost?\t0 = no, 1 = yes\n",
    "- GenHlth:\tWould you say that in general your health is:\t1 = excellent, 2 = very good, 3 = good, 4 = fair, 5 = poor\n",
    "- MentHlth:\tDays of Poor Mental Health (Scale 1-30 days)\t1-30\n",
    "- PhysHlth:\tPhysical Illness or Injury Days in Past 30 Days (Scale 1-30 days)\t1-30\n",
    "- DiffWalk:\tDo you have serious difficulty walking or climbing stairs?\t0 = no, 1 = yes\n",
    "- Sex:\tGender\t0 = female, 1 = male\n",
    "- Age:\t13-Level Age Category\t1 = 18-24, 9 = 60-64, 13 = 80 or older\n",
    "- Education:\tEducation Level (Scale 1-6)\t1 = Never attended school or only kindergarten, 2 = elementary, etc.\n",
    "- Income:\tIncome Scale (Scale 1-8)\t1 = less than 10,000, 5 = less than 35,000, 8 = $75,000 or more\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8843e7",
   "metadata": {},
   "source": [
    "##### 5. Project Milestones\n",
    "\n",
    "The project will be structured into several distinct phases:\n",
    "\n",
    "Phase 1: Data Collection and Preprocessing\n",
    "- Obtain and preprocess the dataset, addressing missing values and outliers.\n",
    "- Conduct exploratory data analysis (EDA) to extract initial insights.\n",
    "\n",
    "Phase 2: Model Selection and Training\n",
    "- Choose appropriate classification algorithms (e.g., logistic regression, decision trees, random forests, support vector machines).\n",
    "- Divide the dataset into training and testing sets.\n",
    "- Train and optimize the machine learning model to maximize prediction accuracy.\n",
    "\n",
    "Phase 3: Evaluation and Validation\n",
    "- Assess the model's performance using relevant metrics (e.g., accuracy, precision, recall, F1-score).\n",
    "- Implement cross-validation to validate model robustness.\n",
    "- Validate the model using an independent dataset (if available) to assess its generalization capability.\n",
    "\n",
    "Phase 4: Deployment and Integration\n",
    "- Developing a user-friendly interface for the diabetes prediction tool.\n",
    "\n",
    "Phase 5: Reporting and Documentation\n",
    "- Produce a comprehensive project report encompassing methodology, results, and recommendations.\n",
    "- Document the codebase and model architecture for future reference.\n",
    "\n",
    "##### 6. Expected Outcomes\n",
    "\n",
    "Upon completion of this project, we anticipate the following outcomes:\n",
    "- A well-performing machine learning model for diabetes prediction.\n",
    "- Valuable insights into the key factors influencing diabetes risk.\n",
    "- A user-friendly tool for diabetes risk assessment that can contribute to improving public health.\n",
    "\n",
    "##### 7. Conclusion\n",
    "This project aspires to harness the capabilities of machine learning to address the pressing issue of diabetes prediction. By accurately identifying individuals at risk of diabetes, we aim to enable timely intervention and improved health outcomes. We are eager to embark on this project and contribute to advancing healthcare through data-driven insights and predictive modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3c1c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
